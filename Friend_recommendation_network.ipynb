{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kx55fqzzRuK7"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import random\n",
        "import math\n",
        "import csv\n",
        "import datetime\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "import multiprocessing as mp\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CommonNeighbors(u, v, g):\n",
        "    u_neighbors = set(g.neighbors(u))\n",
        "    v_neighbors = set(g.neighbors(v))\n",
        "    return len(u_neighbors.intersection(v_neighbors))\n",
        "def common_neighbors(g, edges):\n",
        "    result = []\n",
        "    for edge in edges:\n",
        "        node_one, node_two = edge[0], edge[1]\n",
        "        num_common_neighbors = 0\n",
        "        try:\n",
        "            neighbors_one, neighbors_two = g.neighbors(node_one), g.neighbors(node_two)\n",
        "            for neighbor in neighbors_one:\n",
        "                if neighbor in neighbors_two:\n",
        "                    num_common_neighbors += 1\n",
        "            result.append((node_one, node_two, num_common_neighbors))\n",
        "        except:\n",
        "            pass\n",
        "    return result"
      ],
      "metadata": {
        "id": "5TCv2r3IUGdB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AdamicAdar(u, v, g):\n",
        "    u_neighbors = set(g.neighbors(u))\n",
        "    v_neighbors = set(g.neighbors(v))\n",
        "    aa = 0\n",
        "    for i in u_neighbors.intersection(v_neighbors):\n",
        "        aa += 1 / math.log(len(g.neighbors(i)))\n",
        "    return aa"
      ],
      "metadata": {
        "id": "P-xwKqp3UMSq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResourceAllocation(u, v, g):\n",
        "    u_neighbors = set(g.neighbors(u))\n",
        "    v_neighbors = set(g.neighbors(v))\n",
        "    ra = 0\n",
        "    for i in u_neighbors.intersection(v_neighbors):\n",
        "        ra += 1 / float(len(g.neighbors(i)))\n",
        "    return ra"
      ],
      "metadata": {
        "id": "Zy_MSicwUUXG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def JaccardCoefficent(u, v, g):\n",
        "    u_neighbors = set(g.neighbors(u))\n",
        "    v_neighbors = set(g.neighbors(v))\n",
        "    return len(u_neighbors.intersection(v_neighbors)) / float(len(u_neighbors.union(v_neighbors)))"
      ],
      "metadata": {
        "id": "KdWdI_U3UYhD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PreferentialAttachment(u, v, g):\n",
        "    return len(g.neighbors(u))*len(g.neighbors(v))"
      ],
      "metadata": {
        "id": "eckbk0BVUak7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AllFeatures(u,v,g1, g2):\n",
        "    '''\n",
        "    the change of features in two consecutive sub graphs\n",
        "    '''\n",
        "    try:\n",
        "        cn = CommonNeighbors(u, v, g2)\n",
        "        aa = AdamicAdar(u, v, g2)\n",
        "        ra = ResourceAllocation(u, v, g2)\n",
        "        jc = JaccardCoefficent(u, v, g2)\n",
        "        pa = PreferentialAttachment(u, v, g2)\n",
        "\n",
        "        delta_cn = cn - CommonNeighbors(u, v, g1)\n",
        "        delta_aa = aa - AdamicAdar(u, v, g1)\n",
        "        delta_ra = ra - ResourceAllocation(u, v, g1)\n",
        "        delta_jc = jc - JaccardCoefficent(u, v, g1)\n",
        "        delta_pa = pa - PreferentialAttachment(u, v, g1)\n",
        "        return {\"cn\":cn, \"aa\": aa, \"ra\":ra, \"jc\":jc, \"pa\":pa,\n",
        "            \"delta_cn\": delta_cn, \"delta_aa\": delta_aa, \"delta_ra\": delta_ra,\n",
        "             \"delta_jc\": delta_jc, \"delta_pa\": delta_pa}\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "NMcAXYR5UhFj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_set = [common_neighbors,\n",
        "                   nx.resource_allocation_index,\n",
        "                   nx.jaccard_coefficient,\n",
        "                   nx.adamic_adar_index,\n",
        "                   nx.preferential_attachment\n",
        "                   ]"
      ],
      "metadata": {
        "id": "SnJcNpelUlqQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def produce_fake_edge(g, neg_g,num_test_edges):\n",
        "    i = 0\n",
        "    while i < num_test_edges:\n",
        "        edge = random.sample(g.nodes(), 2)\n",
        "        try:\n",
        "            shortest_path = nx.shortest_path_length(g,source=edge[0],target=edge[1])\n",
        "            if shortest_path >= 2:\n",
        "                neg_g.add_edge(edge[0],edge[1], positive=\"False\")\n",
        "                i += 1\n",
        "        except:\n",
        "            pass"
      ],
      "metadata": {
        "id": "BDfqi6WTUqYz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_graph_from_file(filename):\n",
        "    print(\"----------------build graph--------------------\")\n",
        "    f = open(filename, \"rb\")\n",
        "    g = nx.read_edgelist(f)\n",
        "    return g"
      ],
      "metadata": {
        "id": "0t-To_FVUuC3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_extraction(g, pos_num, neg_num, neg_mode, neg_distance=2, delete=1):\n",
        "    \"\"\"\n",
        "    :param g:  the graph\n",
        "    :param pos_num: the number of positive samples\n",
        "    :param neg_num: the number of negative samples\n",
        "    :param neg_distance: the distance between two nodes in negative samples\n",
        "    :param delete: if delete ==0, don't delete positive edges from graph\n",
        "    :return: pos_sample is a list of positive edges, neg_sample is a list of negative edges\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"----------------extract positive samples--------------------\")\n",
        "    # randomly select pos_num as test edges\n",
        "    pos_sample = random.sample(g.edges(), pos_num)\n",
        "    sample_g = nx.Graph()\n",
        "    sample_g.add_edges_from(pos_sample, positive=\"True\")\n",
        "    nx.write_edgelist(sample_g, \"sample_positive_\" +str(pos_num)+ \".txt\", data=['positive'])\n",
        "\n",
        "    # adding non-existing edges\n",
        "    print(\"----------------extract negative samples--------------------\")\n",
        "    i = 0\n",
        "    neg_g = nx.Graph()\n",
        "    produce_fake_edge(g,neg_g,neg_num)\n",
        "    nx.write_edgelist(neg_g, \"sample_negative_\" +str(neg_num)+ \".txt\", data=[\"positive\"])\n",
        "    neg_sample = neg_g.edges()\n",
        "    neg_g.add_edges_from(pos_sample,positive=\"True\")\n",
        "    nx.write_edgelist(neg_g, \"sample_combine_\" +str(pos_num + neg_num)+ \".txt\", data=[\"positive\"])\n",
        "\n",
        "    # remove the positive sample edges, the rest is the training set\n",
        "    if delete == 0:\n",
        "        return pos_sample, neg_sample\n",
        "    else:\n",
        "        g.remove_edges_from(pos_sample)\n",
        "        nx.write_edgelist(g, \"training.txt\", data=False)\n",
        "\n",
        "        return pos_sample, neg_sample"
      ],
      "metadata": {
        "id": "1gB7z637U1YH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(g, pos_sample, neg_sample, feature_name, model=\"single\", combine_num=5):\n",
        "\n",
        "    data = []\n",
        "    if model == \"single\":\n",
        "        print (\"-----extract feature:\", feature_name.__name__, \"----------\")\n",
        "        preds = feature_name(g, pos_sample)\n",
        "        feature = [feature_name.__name__] + [i[2] for i in preds]\n",
        "        label = [\"label\"] + [\"Pos\" for i in range(len(feature))]\n",
        "        preds = feature_name(g, neg_sample)\n",
        "        feature1 = [i[2] for i in preds]\n",
        "        feature = feature + feature1\n",
        "        label = label + [\"Neg\" for i in range(len(feature1))]\n",
        "        data = [feature, label]\n",
        "        data = transpose(data)\n",
        "        print(\"----------write the feature to file---------------\")\n",
        "        write_data_to_file(data, \"features_\" + model + \"_\" + feature_name.__name__ + \".csv\")\n",
        "    else:\n",
        "        label = [\"label\"] + [\"1\" for i in range(len(pos_sample))] + [\"0\" for i in range(len(neg_sample))]\n",
        "        for j in feature_name:\n",
        "            print (\"-----extract feature:\", j.__name__, \"----------\")\n",
        "            preds = j(g, pos_sample)\n",
        "\n",
        "            feature = [j.__name__] + [i[2] for i in preds]\n",
        "            preds = j(g, neg_sample)\n",
        "            feature = feature + [i[2] for i in preds]\n",
        "            data.append(feature)\n",
        "\n",
        "        data.append(label)\n",
        "        data = transpose(data)\n",
        "        print(\"----------write the features to file---------------\")\n",
        "        write_data_to_file(data, \"features_\" + model + \"_\" + str(combine_num) + \".csv\")\n",
        "    return data\n",
        "\n",
        "\n",
        "def write_data_to_file(data, filename):\n",
        "    csvfile = open(filename, \"w\")\n",
        "    writer = csv.writer(csvfile)\n",
        "    for i in data:\n",
        "        writer.writerow(i)\n",
        "    csvfile.close()\n",
        "\n",
        "\n",
        "\n",
        "def transpose(data):\n",
        "    return [list(i) for i in zip(*data)]"
      ],
      "metadata": {
        "id": "U6RK8QWvU3jE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(filename=\"twitter_combined.txt\", pos_num=0.1, neg_num=0.1, model=\"combined\", combine_num=1,\n",
        "         feature_name=common_neighbors, neg_mode=\"hard\"):\n",
        "    if combine_num==2:\n",
        "        pos_num=0.008;\n",
        "        neg_num=0.008;\n",
        "    g = create_graph_from_file(filename)\n",
        "    num_edges = g.number_of_edges()\n",
        "    pos_num = int(num_edges * pos_num)\n",
        "    neg_num = int(num_edges * neg_num)\n",
        "    pos_sample, neg_sample = sample_extraction(g, pos_num, neg_num,neg_mode)\n",
        "    train_data = feature_extraction(g, pos_sample, neg_sample, feature_name, model, combine_num)"
      ],
      "metadata": {
        "id": "LVmXChxfU856"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fn=\"/content/drive/MyDrive/SNA/DA - 1/twitter_combined.txt\";\n",
        "cn=2;"
      ],
      "metadata": {
        "id": "yLFCmS9jXSBI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(filename=fn,model=\"combined\",combine_num=cn, feature_name=feature_set, neg_mode=\"easy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXH3-ayqX0L3",
        "outputId": "d1dca027-d09e-4a83-832b-3152bd17331d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------build graph--------------------\n",
            "----------------extract positive samples--------------------\n",
            "----------------extract negative samples--------------------\n",
            "-----extract feature: common_neighbors ----------\n",
            "-----extract feature: resource_allocation_index ----------\n",
            "-----extract feature: jaccard_coefficient ----------\n",
            "-----extract feature: adamic_adar_index ----------\n",
            "-----extract feature: preferential_attachment ----------\n",
            "----------write the features to file---------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=np.loadtxt(open(\"features_combined_\"+str(cn)+\".csv\", \"rb\"), delimiter=\",\", skiprows=1);"
      ],
      "metadata": {
        "id": "54lwrLp8X4bN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l,b=r.shape;"
      ],
      "metadata": {
        "id": "FW1hNRIGX_-J"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(r);"
      ],
      "metadata": {
        "id": "i4d_heSrYArp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_l=int(0.75*l)\n",
        "X_train=r[0:train_l,0:b-1]\n",
        "Y_train=r[0:train_l,b-1]\n",
        "X_test=r[train_l:l,0:b-1]\n",
        "Y_test=r[train_l:l,b-1]\n",
        "X_train = normalize(X_train, axis=0, norm='max')\n",
        "X_test = normalize(X_test, axis=0, norm='max')\n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(X_train)  \n",
        "X_train = scaler.transform(X_train)  \n",
        "X_test = scaler.transform(X_test) "
      ],
      "metadata": {
        "id": "xyPy2FJ0YDnv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mySvm(training, training_labels, testing, testing_labels):\n",
        "    #Support Vector Machine\n",
        "    start = datetime.datetime.now()\n",
        "    clf = svm.SVC()\n",
        "    clf.fit(training, training_labels)\n",
        "    print (\"+++++++++ Finishing training the SVM classifier ++++++++++++\")\n",
        "    result = clf.predict(testing)\n",
        "\n",
        "    print (\"SVM accuracy:\", accuracy_score(testing_labels, result))\n",
        "    #keep the time\n",
        "    finish = datetime.datetime.now()\n",
        "    print ((finish-start).seconds)"
      ],
      "metadata": {
        "id": "55o-IFpRYG0z"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mySvm(X_train,Y_train,X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTmIa7n-YJpY",
        "outputId": "41d140f4-fb5f-4574-9838-5d2a5aabc862"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+++++++++ Finishing training the SVM classifier ++++++++++++\n",
            "SVM accuracy: 0.6770548795629501\n",
            "29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic(training, training_labels, testing, testing_labels):\n",
        "    clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='ovr').fit(training, training_labels)\n",
        "    start = datetime.datetime.now()\n",
        "    clf.fit(training, training_labels)\n",
        "    result=clf.predict(testing)\n",
        "    print (\"+++++++++ Finishing training the Linear classifier ++++++++++++\")\n",
        "    print (\"Linear accuracy:\", accuracy_score(testing_labels, result))\n",
        "    #keep the time\n",
        "    finish = datetime.datetime.now()\n",
        "    print ((finish-start).seconds)"
      ],
      "metadata": {
        "id": "OiHpEV1TY9Z1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic(X_train,Y_train,X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHhe3h8UZAnS",
        "outputId": "cc6d6d04-7305-43a7-bbbc-19b5bcb219d3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+++++++++ Finishing training the Linear classifier ++++++++++++\n",
            "Linear accuracy: 0.6697293270424634\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ANN(training, training_labels, testing, testing_labels):\n",
        "    clf = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(15,9), random_state=1)\n",
        "    start = datetime.datetime.now()\n",
        "    clf.fit(training, training_labels)\n",
        "    print (\"+++++++++ Finishing training the ANN classifier ++++++++++++\")\n",
        "    result = clf.predict(testing)\n",
        "\n",
        "    print (\"ANN accuracy:\", accuracy_score(testing_labels, result))\n",
        "    #keep the time\n",
        "    finish = datetime.datetime.now()\n",
        "    print ((finish-start).seconds)"
      ],
      "metadata": {
        "id": "pRSnmpfyZFYV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANN(X_train,Y_train,X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ry6GTCmZGRC",
        "outputId": "ce7f03fd-a2fd-4e31-dde3-270379844d54"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+++++++++ Finishing training the ANN classifier ++++++++++++\n",
            "ANN accuracy: 0.6784206605413459\n",
            "11\n"
          ]
        }
      ]
    }
  ]
}